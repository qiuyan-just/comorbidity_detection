{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXT 文件已生成并处理空格和换行符！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "# 读取 Excel 文件\n",
    "file_path = \"E:/comorbidity/models/症状_BSI/BSI-18.xlsx\"  # 修改为你的 Excel 文件路径\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "post_content_column = '症状'  # 根据你的实际列名修改\n",
    "\n",
    "# 提取该列的数据并去除空值\n",
    "df[post_content_column] = df[post_content_column].apply(lambda x: str(x).replace('\\n', ' ').replace('\\r', ' '))\n",
    "post_contents = df[post_content_column].dropna()\n",
    "\n",
    "# 清理每一条发帖内容\n",
    "cleaned_contents = []\n",
    "\n",
    "for post in post_contents:\n",
    "    # 去除前后空格\n",
    "    post = str(post)\n",
    "    post = post.strip()\n",
    "    \n",
    "    # 替换文本中的换行符（可选：你可以选择去掉或替换为其他符号）\n",
    "    post = post.replace('\\n', '').replace('\\r', '')  # 将换行符替换为空格\n",
    "    \n",
    "    # 替换多个空格为一个空格\n",
    "    post = ' '.join(post.split())\n",
    "    \n",
    "    cleaned_contents.append(post)\n",
    "\n",
    "# 将清理后的内容写入到 TXT 文件\n",
    "with open('symptom_BSI.txt', 'w', encoding='utf-8') as f:\n",
    "    for post in cleaned_contents:\n",
    "        f.write(post + '\\n')\n",
    "\n",
    "print(\"TXT 文件已生成并处理空格和换行符！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取文件内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本内容：  19 头晕或晕倒\n"
     ]
    }
   ],
   "source": [
    "# 注意读取中文时，设置encoding='utf-8'\n",
    "with open('E:/comorbidity/models/症状_BSI/symptom_BSI.txt', 'r', encoding='utf-8') as file:\n",
    "    docs = file.read().split('\\n')\n",
    "    print('文本内容： ', len(docs), docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载停用词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "停用词： ['———', '》），', '）÷（１－', '..', '”，']\n"
     ]
    }
   ],
   "source": [
    "# jieba.load_userdict(\"E:/comorbidity/data/userdict.txt\")\n",
    "stopwords = [line.strip() for line in open(\n",
    "    'stopwords.txt', encoding='UTF-8').readlines()]\n",
    "print('停用词：', stopwords[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#分词处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['头晕', '晕倒']\n",
      "1 ['事物', '不感兴趣']\n",
      "2 ['神经过敏', '心中', '踏实']\n",
      "3 ['胸痛']\n",
      "4 ['感到', '孤独']\n",
      "5 ['感到', '紧张', '容易', '紧张']\n",
      "6 ['恶心', '胃部', '舒服']\n",
      "7 ['感到', '苦闷']\n",
      "8 ['无缘无故', '突然', '感到', '害怕']\n",
      "9 ['呼吸', '困难']\n",
      "10 ['感到', '没有', '价值']\n",
      "11 ['一阵阵', '恐惧', '惊恐']\n",
      "12 ['身体', '发麻', '刺痛']\n",
      "13 ['感到', '没有', '前途', '没有', '希望']\n",
      "14 ['感到', '坐立不安', '心神不定']\n",
      "15 ['感到', '身体', '一部分', '软弱无力']\n",
      "16 ['结束', '生命']\n",
      "17 ['感到', '害怕']\n",
      "18 []\n",
      "切词后：  19 头晕 晕倒\n"
     ]
    }
   ],
   "source": [
    "# 分词\n",
    "cutted_text = []\n",
    "for i, line_text in enumerate(docs):\n",
    "    if len(line_text) > 512:\n",
    "      line_text = line_text[:512] # ⚠️这里可以只保留前512个字符，以保证参与切词的文本，和参与生成词向量的文本，都是512个字符\n",
    "      # print('文本过长，仅保留前512个字符：', i, line_text)\n",
    "    seg_list = jieba.cut(line_text)\n",
    "    # 过滤\n",
    "    filtered_words = []\n",
    "    for word in seg_list:\n",
    "       if (word not in stopwords and (len(word)) >= 2 and not word.isdigit()): # 去除停用词 and 单词长度>=2 and 不能是纯数字\n",
    "          filtered_words.append(word)\n",
    "    print(i, filtered_words)\n",
    "    cutted_text.append(' '.join(filtered_words))\n",
    "\n",
    "print('切词后： ', len(cutted_text), cutted_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存分词文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:/comorbidity/models/症状_BSI/BSI_分词.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(cutted_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已成功转换并保存为 E:/comorbidity/models/症状_BSI/BSI_分词的excel.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 读取 .txt 文件，每行作为一个文本项\n",
    "file_path = 'E:/comorbidity/models/症状_BSI/BSI_分词.txt'\n",
    "lines = []\n",
    "\n",
    "# 打开并读取文件\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 处理每一行，去除换行符，合并多个空格\n",
    "        line = line.strip()  # 去除首尾的空白符\n",
    "        line = re.sub(r'\\n+', '', line)  # 去掉多余的换行符\n",
    "        line = re.sub(r'\\s{2,}', ' ', line)  # 合并多个空格为一个空格\n",
    "        lines.append(line)\n",
    "\n",
    "# 将每一行文本作为 DataFrame 中的一行\n",
    "df = pd.DataFrame(lines, columns=[\"分词文本\"])\n",
    "\n",
    "# 将 DataFrame 写入 Excel 文件\n",
    "output_path = 'E:/comorbidity/models/症状_BSI/BSI_分词的excel.xlsx'  # 输出的 Excel 文件路径\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"文件已成功转换并保存为 {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiuyan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
