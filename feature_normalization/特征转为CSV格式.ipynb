{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e108fa",
   "metadata": {},
   "source": [
    "# 语义特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e833f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 加载 .npy 文件\n",
    "npy_file = \"E:/comorbidity/feature_list/emb-chinese-mentalbert.npy\"  # 替换为你的 .npy 文件路径\n",
    "data = np.load(npy_file)\n",
    "\n",
    "# 将 numpy 数组转换为 pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存为 .csv 文件\n",
    "csv_file = 'E:/comorbidity/feature_normalization/emb-cn-mentalbert.csv'  # 替换为你想要保存的 .csv 文件路径\n",
    "df.to_csv(csv_file, index=False, encoding='utf-8-sig')  # index=False 让 DataFrame 保存时不包含行索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8fe60",
   "metadata": {},
   "source": [
    "# 主题特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5acc638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:random_state not set so using default value\n",
      "WARNING:root:failed to load state from E:/comorbidity/feature_list/DTM-5个.gensim.state: [Errno 2] No such file or directory: 'E:/comorbidity/feature_list/DTM-5个.gensim.state'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('症状', 0.022700551007552694), ('患者', 0.022598571136687413), ('焦虑', 0.02176656195107239), ('抑郁', 0.0162725228168398), ('中医', 0.01593125901118447), ('医生', 0.015524677480199041), ('失眠', 0.015380379507398009), ('治疗', 0.014583489341469871), ('发作', 0.011506294309164986), ('心理', 0.010576132445706187), ('情绪', 0.009065834026221145), ('紊乱', 0.008386928101896798), ('躯体', 0.007530410950713271), ('植物神经', 0.007337360892952207), ('医院', 0.006897937566009267), ('药物', 0.0066866380504074585), ('惊恐', 0.006593622329989141), ('障碍', 0.006207823519127699), ('导致', 0.005628011974797442), ('疾病', 0.005396643705374734)], [('希望', 0.021193113939525027), ('啊啊啊', 0.018715660688548033), ('微博', 0.018631603962450945), ('视频', 0.01715612451993435), ('患者', 0.014132016600130144), ('世界', 0.01015462202009507), ('开心', 0.009352838488973565), ('健康', 0.009182531261986298), ('快乐', 0.009118114081749342), ('孩子', 0.008349244634337219), ('喜欢', 0.007233896602095201), ('生活', 0.006629474379980719), ('好好', 0.0063702173641513446), ('一年', 0.006194147198968004), ('人生', 0.00616212791228096), ('幸福', 0.005585561872871552), ('加油', 0.005575618616054371), ('活着', 0.005203200075763413), ('分享', 0.004748260013628502), ('生日', 0.00418070267394568)], [('真的', 0.017777593354090883), ('感觉', 0.014979382467571346), ('情绪', 0.012075152478932042), ('好像', 0.011000968677061816), ('事情', 0.01094529062298503), ('痛苦', 0.010431001407632633), ('生活', 0.00850489393378989), ('活着', 0.006916725963584551), ('世界', 0.006687977372224443), ('难过', 0.0059373575984910994), ('朋友', 0.005905657434279599), ('开心', 0.005632103458706088), ('理解', 0.005238280480020119), ('患者', 0.0051148440437389095), ('不想', 0.004998854186655861), ('焦虑', 0.0048968429704245526), ('抑郁', 0.004808982109467974), ('想要', 0.00473958764640743), ('喜欢', 0.004732279971109028), ('感受', 0.004731665920771844)], [('感觉', 0.033343654077571984), ('难受', 0.02072971929889132), ('睡不着', 0.014702974810975397), ('吃药', 0.013424516306867753), ('真的', 0.012798336418409165), ('晚上', 0.01155503744395482), ('有没有', 0.010779963649187468), ('睡觉', 0.010528217102479594), ('特别', 0.010178346365210405), ('医院', 0.009474847996353862), ('害怕', 0.009422109200624964), ('医生', 0.00873564098428054), ('焦虑', 0.008685031788880984), ('舒服', 0.007907091192713035), ('小时', 0.006683838216524196), ('心脏', 0.00663131635292333), ('身体', 0.005422651118792247), ('早上', 0.005251866965835155), ('失眠', 0.0050463886997439015), ('几天', 0.005024479118680589)], [('真的', 0.029931151231912655), ('不想', 0.020848072534319452), ('学校', 0.010628801547388735), ('工作', 0.010289957079267293), ('妈妈', 0.009905419980103056), ('讨厌', 0.008903300667957402), ('朋友', 0.00814341971196986), ('感觉', 0.007125135141227094), ('家里', 0.00694941305071507), ('不好', 0.006249380674454377), ('东西', 0.006128548316861409), ('回家', 0.0059795384766941585), ('喜欢', 0.0055589091607451445), ('难受', 0.005482566725681212), ('特别', 0.0054097012731393465), ('老师', 0.005283251824320754), ('焦虑', 0.005125121743296243), ('父母', 0.00483638677779499), ('上班', 0.004599961192252006), ('上学', 0.004487390324308831)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# 加载模型\n",
    "ldaseq_loaded = LdaModel.load(\"E:/comorbidity/feature_list/DTM-5个.gensim\")\n",
    "\n",
    "# 打印模型的一些信息，检查是否加载成功\n",
    "print(ldaseq_loaded.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b9fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！结果已保存到 doc_topic_5.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 获取主题数量\n",
    "num_topics = ldaseq_loaded.num_topics\n",
    "total_docs = 95163  # 总文档数\n",
    "\n",
    "# 生成动态表头\n",
    "header = [\"文档ID\"] + [f\"主题{i}\" for i in range(num_topics)] + [\"主主题\"]\n",
    "\n",
    "with open(\"E:/comorbidity/feature_normalization/doc_topic_5.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)  # 写入新表头\n",
    "    \n",
    "    for doc_id in range(total_docs):\n",
    "        # 获取主题概率分布\n",
    "        topic_dist = ldaseq_loaded.doc_topics(doc_id)\n",
    "        \n",
    "        # 转换为概率列表\n",
    "        prob_list = [round(prob, 4) for prob in topic_dist]  # 保留4位小数\n",
    "        \n",
    "        # 找到主主题\n",
    "        main_topic = topic_dist.argmax()\n",
    "        \n",
    "        # 组合行数据\n",
    "        row = [doc_id] + prob_list + [main_topic]\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"处理完成！结果已保存到 doc_topic_5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c28e27b",
   "metadata": {},
   "source": [
    "# 情绪特征（0-1标准化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74274533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in c:\\users\\16437\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f0e640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到编码格式: ISO-8859-1\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "with open(\"E:/comorbidity/feature_list/cnsenti情绪结果.csv\", 'rb') as f:\n",
    "    rawdata = f.read(10000)  # 读取前10000字节用于检测\n",
    "    encoding = chardet.detect(rawdata)['encoding']\n",
    "print(f\"检测到编码格式: {encoding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ef193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "成功处理 95163 条数据！\n",
      "结果文件已保存至: E:/comorbidity/feature_normalization/emotion_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定文件路径\n",
    "file_path = \"E:/comorbidity/feature_list/cnsenti情绪结果.csv\"\n",
    "output_path = \"E:/comorbidity/feature_normalization/emotion_results.csv\"\n",
    "\n",
    "# 定义情感列\n",
    "emotion_columns = ['好', '乐', '哀', '怒', '惧', '恶', '惊']\n",
    "\n",
    "# 1. 读取文件（明确使用GB2312编码）\n",
    "df = pd.read_csv(file_path, encoding='GB2312')\n",
    "\n",
    "# 2. 检查列名是否匹配\n",
    "missing_cols = [col for col in emotion_columns if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"CSV文件中缺少以下列: {missing_cols}\")\n",
    "\n",
    "# 3. 归一化处理\n",
    "df_normalized = df.copy()\n",
    "row_sums = df_normalized[emotion_columns].sum(axis=1)\n",
    "safe_row_sums = row_sums.replace(0, 1)  # 避免除零错误\n",
    "df_normalized[emotion_columns] = df_normalized[emotion_columns].div(safe_row_sums, axis=0).round(4)\n",
    "\n",
    "# 4. 保存结果（使用通用编码）\n",
    "df_normalized.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 输出结果\n",
    "print(\"=\"*50)\n",
    "print(f\"成功处理 {len(df)} 条数据！\")\n",
    "print(f\"结果文件已保存至: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df287c",
   "metadata": {},
   "source": [
    "# 情感极性+情感强度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91f86fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "成功处理 95163 条数据\n",
      "结果文件列结构：\n",
      "| 负向   | 中性   | 正向   |   情感强度_归一化 |\n",
      "|:-------|:-------|:-------|------------------:|\n",
      "| True   | False  | False  |          0.2      |\n",
      "| True   | False  | False  |          0        |\n",
      "| True   | False  | False  |          0.266667 |\n",
      "文件已保存至：E:/comorbidity/feature_normalization/sentiment_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_emotion_data(input_path, output_path):\n",
    "    \"\"\"\n",
    "    处理情感分析数据并输出CSV文件\n",
    "    参数：\n",
    "    input_path: 输入Excel文件路径\n",
    "    output_path: 输出CSV文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. 读取Excel文件\n",
    "        df = pd.read_excel(input_path)\n",
    "        \n",
    "        # 2. 验证数据列是否存在\n",
    "        required_columns = ['最终的情感分析结果', '情感强度']\n",
    "        missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"文件缺少必要列：{', '.join(missing_cols)}\")\n",
    "\n",
    "        # 3. 数据预处理\n",
    "        # 确保情感强度为数值类型\n",
    "        df['情感强度'] = pd.to_numeric(df['情感强度'], errors='coerce')\n",
    "        \n",
    "        # 4. One-Hot编码\n",
    "        onehot = pd.get_dummies(\n",
    "            df['最终的情感分析结果'],\n",
    "            prefix='',\n",
    "            prefix_sep='',\n",
    "            columns=['负向', '中性', '正向']  # 显式指定所有可能类别\n",
    "        ).reindex(columns=['负向', '中性', '正向'], fill_value=0)\n",
    "        \n",
    "        # 5. 情感强度归一化\n",
    "        min_val = df['情感强度'].min()\n",
    "        max_val = df['情感强度'].max()\n",
    "        range_val = max_val - min_val\n",
    "        \n",
    "        if range_val == 0:\n",
    "            # 处理全零或恒定值情况\n",
    "            normalized = 0.0\n",
    "        else:\n",
    "            normalized = (df['情感强度'] - min_val) / range_val\n",
    "        \n",
    "        # 6. 创建结果DataFrame\n",
    "        result = pd.concat([\n",
    "            onehot,\n",
    "            normalized.rename('情感强度_归一化')\n",
    "        ], axis=1)\n",
    "        \n",
    "        # 7. 保存结果\n",
    "        result.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(\"=\"*40)\n",
    "        print(f\"成功处理 {len(df)} 条数据\")\n",
    "        print(\"结果文件列结构：\")\n",
    "        print(result.head(3).to_markdown(index=False))\n",
    "        print(f\"文件已保存至：{output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"=\"*40)\n",
    "        print(\"处理失败，错误信息：\")\n",
    "        print(str(e))\n",
    "        print(\"=\"*40)\n",
    "        print(\"常见问题排查：\")\n",
    "        print(\"1. 确认Excel文件路径是否正确\")\n",
    "        print(\"2. 检查Excel文件是否被其他程序打开\")\n",
    "        print(\"3. 验证数据列是否包含中文标点\")\n",
    "\n",
    "# 使用示例\n",
    "input_excel = \"E:/comorbidity/feature_list/修正BOSON情感分析结果+情感强度.xlsx\"  # 修改为实际路径\n",
    "output_csv = \"E:/comorbidity/feature_normalization/sentiment_results.csv\"\n",
    "\n",
    "process_emotion_data(input_excel, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc9317",
   "metadata": {},
   "source": [
    "# 社交行为特征——帖子层面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d11bdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "成功处理 95163 条数据\n",
      "各列范围：\n",
      "转发：0~1000 → 归一化范围：0.00~1.00\n",
      "评论：0~307 → 归一化范围：0.00~1.00\n",
      "点赞：0~5016 → 归一化范围：0.00~1.00\n",
      "文件已保存至：E:/comorbidity/feature_normalization/post.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_social_data(input_path, output_path):\n",
    "    \"\"\"\n",
    "    处理社交媒体数据并输出CSV文件\n",
    "    参数：\n",
    "    input_path: 输入Excel文件路径\n",
    "    output_path: 输出CSV文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ========== 数据读取 ==========\n",
    "        df = pd.read_excel(input_path, engine='openpyxl')\n",
    "        \n",
    "        # ========== 数据验证 ==========\n",
    "        required_columns = ['数据来源', '转发', '评论', '点赞']\n",
    "        missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"文件缺少必要列：{', '.join(missing_cols)}\")\n",
    "\n",
    "        # ========== 数据处理 ==========\n",
    "        # 1. 数据来源One-Hot编码\n",
    "        source_encoded = pd.get_dummies(\n",
    "            df['数据来源'], \n",
    "            prefix='来源'\n",
    "        )\n",
    "        \n",
    "        # 2. 数值列归一化（列归一化）\n",
    "        numeric_cols = ['转发', '评论', '点赞']\n",
    "        df_normalized = df[numeric_cols].copy()\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            min_val = df_normalized[col].min()\n",
    "            max_val = df_normalized[col].max()\n",
    "            \n",
    "            # 处理特殊值\n",
    "            if max_val == min_val:\n",
    "                df_normalized[col] = 0.0\n",
    "            else:\n",
    "                df_normalized[col] = (df_normalized[col] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            df_normalized[col] = df_normalized[col].round(4)\n",
    "\n",
    "        # ========== 结果合并 ==========\n",
    "        result = pd.concat([source_encoded, df_normalized], axis=1)\n",
    "        \n",
    "        # ========== 结果保存 ==========\n",
    "        result.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # ========== 输出验证 ==========\n",
    "        print(\"=\"*50)\n",
    "        print(f\"成功处理 {len(df)} 条数据\")\n",
    "        print(\"各列范围：\")\n",
    "        print(f\"转发：{df['转发'].min()}~{df['转发'].max()} → 归一化范围：{df_normalized['转发'].min():.2f}~{df_normalized['转发'].max():.2f}\")\n",
    "        print(f\"评论：{df['评论'].min()}~{df['评论'].max()} → 归一化范围：{df_normalized['评论'].min():.2f}~{df_normalized['评论'].max():.2f}\")\n",
    "        print(f\"点赞：{df['点赞'].min()}~{df['点赞'].max()} → 归一化范围：{df_normalized['点赞'].min():.2f}~{df_normalized['点赞'].max():.2f}\")\n",
    "        print(f\"文件已保存至：{output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"=\"*50)\n",
    "        print(\"处理失败，错误信息：\")\n",
    "        print(str(e))\n",
    "        print(\"=\"*50)\n",
    "        print(\"排查建议：\")\n",
    "        print(\"1. 检查Excel中是否包含非数字字符\")\n",
    "        print(\"2. 确认数值列数据为整数型\")\n",
    "\n",
    "# 正确调用方式（参数名与定义一致）\n",
    "process_social_data(\n",
    "    input_path=\"E:/comorbidity/data/final_data.xlsx\",\n",
    "    output_path=\"E:/comorbidity/feature_normalization/post.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536d5c8",
   "metadata": {},
   "source": [
    "# 社交行为特征——用户层面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cac152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功处理 95163 条数据\n",
      "各列归一化范围：\n",
      "     发帖强度  互动率  粉丝关注比\n",
      "min   0.0  0.0    0.0\n",
      "max   1.0  1.0    1.0\n",
      "结果文件已保存至：E:/comorbidity/feature_normalization/user.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_excel_data(input_path, output_path):\n",
    "    \"\"\"\n",
    "    处理Excel社交媒体数据\n",
    "    :param input_path: 输入Excel文件路径\n",
    "    :param output_path: 输出CSV文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ========== 读取Excel文件 ==========\n",
    "        df = pd.read_excel(input_path, engine='openpyxl')\n",
    "        \n",
    "        # ========== 数据验证 ==========\n",
    "        required_cols = ['序号', '发帖强度', '互动率', '粉丝关注比', '高影响力用户']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"文件缺少必要列：{', '.join(missing_cols)}\")\n",
    "\n",
    "        # ========== 数据类型转换 ==========\n",
    "        # 转换布尔列（处理Excel中的TRUE/FALSE可能被读取为字符串的情况）\n",
    "        df['高影响力用户'] = df['高影响力用户'].astype(str).str.upper().map({'TRUE': 1, 'FALSE': 0}).astype(bool)\n",
    "\n",
    "        # ========== 数值列归一化 ==========\n",
    "        numeric_cols = ['发帖强度', '互动率', '粉丝关注比']\n",
    "        df_normalized = df[numeric_cols].copy()\n",
    "        \n",
    "        # 创建归一化器函数\n",
    "        def normalize_col(col_series):\n",
    "            min_val = col_series.min()\n",
    "            max_val = col_series.max()\n",
    "            if max_val == min_val:\n",
    "                return pd.Series([0.0]*len(col_series), name=col_series.name)\n",
    "            return (col_series - min_val) / (max_val - min_val)\n",
    "        \n",
    "        # 应用归一化并保留4位小数\n",
    "        df_normalized = df_normalized.apply(normalize_col).round(4)\n",
    "        \n",
    "        # ========== One-Hot编码 ==========\n",
    "        influence_encoded = pd.get_dummies(\n",
    "            df['高影响力用户'],\n",
    "            prefix='高影响力用户',\n",
    "            columns=['True', 'False'],\n",
    "            dtype=int\n",
    "        )\n",
    "        \n",
    "        # ========== 合并结果 ==========\n",
    "        result = pd.concat([\n",
    "            df[['序号']],\n",
    "            df_normalized,\n",
    "            influence_encoded\n",
    "        ], axis=1)\n",
    "        \n",
    "        # ========== 保存结果 ==========\n",
    "        result.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # ========== 打印处理摘要 ==========\n",
    "        print(f\"成功处理 {len(df)} 条数据\")\n",
    "        print(\"各列归一化范围：\")\n",
    "        print(df_normalized.agg(['min', 'max']).round(4))\n",
    "        print(f\"结果文件已保存至：{output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"=\"*40)\n",
    "        print(\"处理失败，错误信息：\")\n",
    "        print(str(e))\n",
    "        print(\"=\"*40)\n",
    "        print(\"常见问题排查：\")\n",
    "        print(\"1. 确认Excel文件格式为.xlsx（2007+版本）\")\n",
    "        print(\"2. 检查Excel中是否包含隐藏字符或合并单元格\")\n",
    "        print(\"3. 验证数值列是否包含非数字内容\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    process_excel_data(\n",
    "        input_path=\"E:/comorbidity/feature_list/用户社交特征.xlsx\",  # 修改为实际路径\n",
    "        output_path=\"E:/comorbidity/feature_normalization/user.csv\"  # 修改为实际路径\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726b8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功处理 95163 条数据\n",
      "各列归一化范围：\n",
      "     发帖强度  互动强度  粉丝关注比\n",
      "min   0.0   0.0    0.0\n",
      "max   1.0   1.0    1.0\n",
      "结果文件已保存至：E:/comorbidity/feature_normalization/user33.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_excel_data(input_path, output_path):\n",
    "    \"\"\"\n",
    "    处理Excel社交媒体数据\n",
    "    :param input_path: 输入Excel文件路径\n",
    "    :param output_path: 输出CSV文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ========== 读取Excel文件 ==========\n",
    "        df = pd.read_excel(input_path, engine='openpyxl')\n",
    "        \n",
    "        # ========== 数据验证 ==========\n",
    "        required_cols = ['序号', '发帖强度', '互动强度', '粉丝关注比']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"文件缺少必要列：{', '.join(missing_cols)}\")\n",
    "\n",
    "        # ========== 数据类型转换 ==========\n",
    "        # 转换布尔列（处理Excel中的TRUE/FALSE可能被读取为字符串的情况）\n",
    "        # df['高影响力用户'] = df['高影响力用户'].astype(str).str.upper().map({'TRUE': 1, 'FALSE': 0}).astype(bool)\n",
    "\n",
    "        # ========== 数值列归一化 ==========\n",
    "        numeric_cols = ['发帖强度', '互动强度', '粉丝关注比']\n",
    "        df_normalized = df[numeric_cols].copy()\n",
    "        \n",
    "        # 创建归一化器函数\n",
    "        def normalize_col(col_series):\n",
    "            min_val = col_series.min()\n",
    "            max_val = col_series.max()\n",
    "            if max_val == min_val:\n",
    "                return pd.Series([0.0]*len(col_series), name=col_series.name)\n",
    "            return (col_series - min_val) / (max_val - min_val)\n",
    "        \n",
    "        # 应用归一化并保留4位小数\n",
    "        df_normalized = df_normalized.apply(normalize_col).round(4)\n",
    "        \n",
    "        # ========== One-Hot编码 ==========\n",
    "        # influence_encoded = pd.get_dummies(\n",
    "        #     df['高影响力用户'],\n",
    "        #     prefix='高影响力用户',\n",
    "        #     columns=['True', 'False'],\n",
    "        #     dtype=int\n",
    "        # )\n",
    "        \n",
    "        # ========== 合并结果 ==========\n",
    "        result = pd.concat([\n",
    "            df[['序号']],\n",
    "            df_normalized\n",
    "        ], axis=1)\n",
    "        \n",
    "        # ========== 保存结果 ==========\n",
    "        result.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # ========== 打印处理摘要 ==========\n",
    "        print(f\"成功处理 {len(df)} 条数据\")\n",
    "        print(\"各列归一化范围：\")\n",
    "        print(df_normalized.agg(['min', 'max']).round(4))\n",
    "        print(f\"结果文件已保存至：{output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"=\"*40)\n",
    "        print(\"处理失败，错误信息：\")\n",
    "        print(str(e))\n",
    "        print(\"=\"*40)\n",
    "        print(\"常见问题排查：\")\n",
    "        print(\"1. 确认Excel文件格式为.xlsx（2007+版本）\")\n",
    "        print(\"2. 检查Excel中是否包含隐藏字符或合并单元格\")\n",
    "        print(\"3. 验证数值列是否包含非数字内容\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    process_excel_data(\n",
    "        input_path=\"E:/comorbidity/feature_list/用户社交特征33.xlsx\",  # 修改为实际路径\n",
    "        output_path=\"E:/comorbidity/feature_normalization/user33.csv\"  # 修改为实际路径\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ba6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiuyan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
